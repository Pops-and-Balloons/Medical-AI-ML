{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660ddfe-9ed8-41f5-adb5-c4180d0d4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 0. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modules from Scikit-learn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "\n",
    "# 주피터 노트북 내에서 그래프를 바로 볼 수 있도록 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 1. EDA - Exploratory Data Analysis\n",
    "df = pd.read_csv('유방 dataset.csv')\n",
    "\n",
    "# head 5줄로 내용 확인\n",
    "print(\"### Check head 5 ###\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 데이터의 전체적인 정보(컬럼별 데이터 타입, Null 값 유무)를 확인\n",
    "# 'Unnamed: 32' 컬럼에 모든 값이 Null(결측치)인 것을 확인할 수 있음\n",
    "print(\"### 데이터 정보 요약 ###\")\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 2. Preprocessing\n",
    "# 불필요한 컬럼 제거, 데이터를 정리\n",
    "\n",
    "# 'id' 컬럼과 모든 값이 비어있는 'Unnamed: 32' 컬럼을 제거\n",
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "\n",
    "# 'diagnosis' 컬럼의 값을 머신러닝 모델이 이해할 수 있도록 숫자 형태로 변환\n",
    "# 악성(Malignant)은 1, 양성(Benign)은 0\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# 전처리 중간확인\n",
    "print(\"### 전처리 후 데이터 상위 5개 행 ###\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 3. Visualization\n",
    "# 데이터의 특징과 분포 그래프화\n",
    "\n",
    "# 1. 악성(1)과 양성(0) 종양의 개수 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='diagnosis', data=df)\n",
    "plt.title('Diagnosis Distribution (1: Malignant, 0: Benign)')\n",
    "plt.xlabel('Diagnosis')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. 각 특징(feature)들 간의 상관관계를 히트맵으로 시각화\n",
    "# 어떤 특징들이 서로 관련이 깊은지 한눈에 확인 가능\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.show()\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 4. 학습을 위한 데이터 준비\n",
    "# feature (X)와 label (y), train/test dataset 설정\n",
    "\n",
    "# 'diagnosis' 컬럼을 제외한 모든 컬럼을 X (특징 데이터)로 설정\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "# 'diagnosis' 컬럼을 y (타겟 데이터)로 설정\n",
    "y = df['diagnosis']\n",
    "\n",
    "# 전체 데이터를 train (80%)과 test (20%)으로 분리\n",
    "# random_state=42는 코드를 다시 실행해도 항상 똑같은 방식으로 데이터가 나뉘도록 보장\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 5. Feature Scaling\n",
    "# 각 데이터의 단위와 범위를 맞춰주어 모델이 더 안정적으로 학습\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# X_train를 기준으로 스케일러를 학습(fit)시키고, 변환(transform)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# X_test는 학습용 데이터 기준으로 변환만 수행 (중요)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 6. ML model 학습 및 평가\n",
    "\n",
    "# ### Model 1: Logistic Regression\n",
    "print(\"### Model 1: Logistic Regression ###\")\n",
    "# 모델을 생성하고 학습\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "pred_lr = model_lr.predict(X_test_scaled)\n",
    "# ROC Curve를 위한 확률값 계산 코드\n",
    "proba_lr = model_lr.predict_proba(X_test_scaled)[:, 1]\n"
    "\n",
    "# 성능 평가\n",
    "accuracy_lr = accuracy_score(y_test, pred_lr)\n",
    "precision_lr = precision_score(y_test, pred_lr)\n",
    "recall_lr = recall_score(y_test, pred_lr)\n",
    "f1_lr = f1_score(y_test, pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, model_lr.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy_lr:.4f}\")\n",
    "print(f\"Precision: {precision_lr:.4f}\")\n",
    "print(f\"Recall: {recall_lr:.4f}\")\n",
    "print(f\"F1 Score: {f1_lr:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr:.4f}\")\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "cm_lr = confusion_matrix(y_test, pred_lr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ### Model 2: Random Forest\n",
    "print(\"### Model 2: Random Forest ###\")\n",
    "# 모델을 생성하고 학습\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "pred_rf = model_rf.predict(X_test_scaled)\n",
    "proba_rf = model_rf.predict_proba(X_test_scaled)[:, 1]\n"
    "\n",
    "# 성능을 평가\n",
    "accuracy_rf = accuracy_score(y_test, pred_rf)\n",
    "precision_rf = precision_score(y_test, pred_rf)\n",
    "recall_rf = recall_score(y_test, pred_rf)\n",
    "f1_rf = f1_score(y_test, pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, model_rf.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1 Score: {f1_rf:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf:.4f}\")\n",
    "\n",
    "# Confusion Matrix을 시각화\n",
    "cm_rf = confusion_matrix(y_test, pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ### Model 3: Support Vector Machine - SVM\n",
    "print(\"### Model 3: Support Vector Machine (SVM) ###\")\n",
    "# 모델을 생성하고 학습\n",
    "model_svm = SVC(probability=True, random_state=42)\n",
    "model_svm.fit(X_train_scaled, y_train)\n",
    "pred_svm = model_svm.predict(X_test_scaled)\n",
    "proba_svm = model_svm.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 성능을 평가\n",
    "accuracy_svm = accuracy_score(y_test, pred_svm)\n",
    "precision_svm = precision_score(y_test, pred_svm)\n",
    "recall_svm = recall_score(y_test, pred_svm)\n",
    "f1_svm = f1_score(y_test, pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, proba_svm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {precision_svm:.4f}\")\n",
    "print(f\"Recall: {recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_svm:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_svm:.4f}\")\n",
    "\n",
    "# Confusion Matrix을 시각화\n",
    "cm_svm = confusion_matrix(y_test, pred_svm)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - SVM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 4. Comparison of Models: ROC AUC Curve\n",
    "\n",
    "# 각 모델의 ROC Curve 계산\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, proba_rf)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, proba_svm)\n",
    "# ROC Curve 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.4f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.4f})')\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {roc_auc_svm:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "\n",
    "plt.title('ROC AUC Curve for All Models')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ## 7. 결론\n",
    "#  모델의 성능을 비교\n",
    "\n",
    "print(\"### 최종 성능 비교 ###\")\n",
    "results = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'SVM'],\n",
    "    'Accuracy': [accuracy_lr, accuracy_rf, accuracy_svm],\n",
    "    'Precision': [precision_lr, precision_rf, precision_svm],\n",
    "    'Recall': [recall_lr, recall_rf, recall_svm],\n",
    "    'F1 Score': [f1_lr, f1_rf, f1_svm],\n",
    "    'ROC AUC': [roc_auc_lr, roc_auc_rf, roc_auc_svm]\n",
    "}\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
